# README.md




```python
import requests
import google.auth
from google.auth.transport.requests import Request
import json
import time

# èªè¨¼ãƒˆãƒ¼ã‚¯ãƒ³ã®å–å¾—
credentials, _ = google.auth.default()
credentials.refresh(Request())
access_token = credentials.token

# Vertex AI ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
PROJECT_ID = "your-project-id"
LOCATION = "us-central1"
MODEL_ID = "gemini-pro"
ENDPOINT = f"https://{LOCATION}-aiplatform.googleapis.com/v1/projects/{PROJECT_ID}/locations/{LOCATION}/publishers/google/models/{MODEL_ID}:streamGenerateContent"

# ãƒ˜ãƒƒãƒ€ãƒ¼
headers = {
    "Authorization": f"Bearer {access_token}",
    "Content-Type": "application/json",
    "Accept": "text/event-stream"
}

# ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒœãƒ‡ã‚£
data = {
    "contents": [
        {"role": "user", "parts": [{"text": "Tell me about machine learning."}]}
    ],
    "generationConfig": {
        "temperature": 0.7,
        "top_p": 0.9,
        "max_output_tokens": 1024
    }
}

# æœ€å¤§ãƒªãƒˆãƒ©ã‚¤å›æ•°
MAX_RETRIES = 5

def convert_messages_to_vertexai(messages):
    converted = []
    for message in messages:
        if isinstance(message, SystemMessage):
            converted.append({"role": "user", "parts": [{"text": message.content}]})  # SystemMessage ã‚‚ "user"
        elif isinstance(message, HumanMessage):
            converted.append({"role": "user", "parts": [{"text": message.content}]})
        elif isinstance(message, AIMessage):
            converted.append({"role": "model", "parts": [{"text": message.content}]})
    return converted

def call_gemini(retries=0):
    try:
        response = requests.post(ENDPOINT, headers=headers, json=data, stream=True, timeout=15)

        # HTTP ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚³ãƒ¼ãƒ‰ã«ã‚ˆã‚‹ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
        if response.status_code == 400:
            raise ValueError("400 Bad Request: ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’ç¢ºèªã—ã¦ãã ã•ã„")
        elif response.status_code == 401:
            raise PermissionError("401 Unauthorized: èªè¨¼ãƒˆãƒ¼ã‚¯ãƒ³ãŒç„¡åŠ¹ã¾ãŸã¯æœŸé™åˆ‡ã‚Œã§ã™")
        elif response.status_code == 403:
            raise PermissionError("403 Forbidden: æ¨©é™ãŒä¸è¶³ã—ã¦ã„ã¾ã™")
        elif response.status_code == 404:
            raise FileNotFoundError("404 Not Found: ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ URL ãŒé–“é•ã£ã¦ã„ã¾ã™")
        elif response.status_code == 429:
            retry_after = int(response.headers.get("Retry-After", 5))
            print(f"429 Too Many Requests: {retry_after}ç§’å¾Œã«å†è©¦è¡Œã—ã¾ã™")
            time.sleep(retry_after)
            return call_gemini(retries + 1)  # å†è©¦è¡Œ
        elif response.status_code in [500, 503, 504]:
            if retries < MAX_RETRIES:
                wait_time = 2 ** retries  # æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•
                print(f"{response.status_code} ã‚¨ãƒ©ãƒ¼: {wait_time}ç§’å¾Œã«å†è©¦è¡Œï¼ˆ{retries+1}/{MAX_RETRIES}ï¼‰")
                time.sleep(wait_time)
                return call_gemini(retries + 1)  # å†è©¦è¡Œ
            else:
                raise ConnectionError(f"{response.status_code} ã‚µãƒ¼ãƒãƒ¼ã‚¨ãƒ©ãƒ¼: æœ€å¤§ãƒªãƒˆãƒ©ã‚¤å›æ•°ã‚’è¶…ãˆã¾ã—ãŸ")

        # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®å‡¦ç†
        for line in response.iter_lines():
            if line:
                try:
                    event_data = json.loads(line.decode("utf-8").replace("data: ", ""))
                    print(event_data)  # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿
                except json.JSONDecodeError:
                    print("JSON ãƒ‡ã‚³ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼:", line.decode("utf-8"))

    except requests.exceptions.Timeout:
        if retries < MAX_RETRIES:
            wait_time = 2 ** retries
            print(f"ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆç™ºç”Ÿã€‚{wait_time}ç§’å¾Œã«å†è©¦è¡Œï¼ˆ{retries+1}/{MAX_RETRIES}ï¼‰")
            time.sleep(wait_time)
            return call_gemini(retries + 1)  # å†è©¦è¡Œ
        else:
            print("ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆãŒç¶šã„ãŸãŸã‚ã€å‡¦ç†ã‚’ä¸­æ–­ã—ã¾ã™")

    except requests.exceptions.ConnectionError:
        print("ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼: ã‚µãƒ¼ãƒãƒ¼ã«æ¥ç¶šã§ãã¾ã›ã‚“")
    except requests.exceptions.RequestException as e:
        print(f"ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    except Exception as e:
        print(f"äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")

# å®Ÿè¡Œ
call_gemini()

```



```
curl -X POST \
  -H "Authorization: Bearer $(gcloud auth print-access-token)" \
  -H "Content-Type: application/json" \
  -H "Accept: text/event-stream" \
  -d '{
    "contents": [
      {"role": "user", "parts": [{"text": "Tell me a long story."}]}
    ],
    "generationConfig": {
      "temperature": 0.7,
      "top_p": 0.9,
      "max_output_tokens": 1024
    }
  }' 
```


```
import json
import time
import requests
import google.auth
from google.auth.transport.requests import Request

# ğŸ”¹ Google èªè¨¼æƒ…å ±ã®å–å¾—
credentials, project = google.auth.default()
credentials.refresh(Request())

# ğŸ”¹ Vertex AI ã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ & ãƒ¢ãƒ‡ãƒ«
LOCATION = "asia-northeast1"
MODEL_ID = "gemini-pro"
ENDPOINT = f"https://{LOCATION}-aiplatform.googleapis.com/v1/projects/{project}/locations/{LOCATION}/publishers/google/models/{MODEL_ID}:streamGenerateContent"

# ğŸ”¹ API ãƒ˜ãƒƒãƒ€ãƒ¼
headers = {
    "Authorization": f"Bearer {credentials.token}",
    "Content-Type": "application/json"
}

# ğŸ”¹ ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿
data = {
    "model": MODEL_ID,
    "contents": [{"role": "user", "parts": [{"text": "Geminiã«ã¤ã„ã¦500å­—ã§æ•™ãˆã¦"}]}]
}

# ğŸ”¹ `CallbackManager` ã‚¯ãƒ©ã‚¹ï¼ˆã‚¤ãƒ™ãƒ³ãƒˆã”ã¨ã«å°‚ç”¨ã® `execute_*` ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä½œæˆï¼‰
class CallbackManager:
    def execute_start(self):
        """ãƒªã‚¯ã‚¨ã‚¹ãƒˆé–‹å§‹æ™‚ã®å‡¦ç†"""
        print("[INFO] ãƒªã‚¯ã‚¨ã‚¹ãƒˆé–‹å§‹")

    def execute_new_token(self, chunk, elapsed_time):
        """LLM ã‹ã‚‰æ–°ã—ã„ãƒˆãƒ¼ã‚¯ãƒ³ã‚’å—ä¿¡ã—ãŸã¨ãã®å‡¦ç†"""
        try:
            decoded_chunk = json.loads(chunk.decode("utf-8"))
            token = decoded_chunk.get("text", "")  # å—ä¿¡ã—ãŸãƒ†ã‚­ã‚¹ãƒˆéƒ¨åˆ†
            print(f"[{elapsed_time:.2f}s] å—ä¿¡ãƒˆãƒ¼ã‚¯ãƒ³: {token}")
        except json.JSONDecodeError:
            self.execute_llm_error("ç„¡åŠ¹ãªãƒˆãƒ¼ã‚¯ãƒ³ã‚’å—ä¿¡ã—ã¾ã—ãŸ")

    def execute_end(self):
        """ãƒªã‚¯ã‚¨ã‚¹ãƒˆå®Œäº†æ™‚ã®å‡¦ç†"""
        print("[INFO] ãƒªã‚¯ã‚¨ã‚¹ãƒˆçµ‚äº†")

    def execute_llm_error(self, error):
        """LLM ã‹ã‚‰ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚¨ãƒ©ãƒ¼"""
        print(f"[LLM ERROR] {error}")

    def execute_chain_error(self, error):
        """API å‘¼ã³å‡ºã—å…¨ä½“ã®ã‚¨ãƒ©ãƒ¼"""
        print(f"[CHAIN ERROR] {error}")

# ğŸ”¹ `CallbackManager` ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä½œæˆ
callback_manager = CallbackManager()

# ğŸ”¹ API ãƒªã‚¯ã‚¨ã‚¹ãƒˆé€ä¿¡ï¼ˆã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å¯¾å¿œï¼‰
start_time = time.time()

try:
    callback_manager.execute_start()  # ãƒªã‚¯ã‚¨ã‚¹ãƒˆé–‹å§‹

    with requests.post(ENDPOINT, headers=headers, json=data, stream=True) as response:
        if response.status_code != 200:
            raise Exception(f"APIã‚¨ãƒ©ãƒ¼: {response.status_code} {response.text}")

        for chunk in response.iter_lines():
            if chunk:
                elapsed_time = time.time() - start_time
                callback_manager.execute_new_token(chunk, elapsed_time)  # ãƒˆãƒ¼ã‚¯ãƒ³å—ä¿¡

    callback_manager.execute_end()  # ãƒªã‚¯ã‚¨ã‚¹ãƒˆçµ‚äº†

except requests.exceptions.RequestException as e:
    callback_manager.execute_chain_error(str(e))
except Exception as e:
    callback_manager.execute_chain_error(str(e))

```
